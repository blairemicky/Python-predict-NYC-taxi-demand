{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('testing RMSE:', 2.6335145069822397e+18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "nycmodel=pd.read_csv('nycmodeldata.csv', sep='\\t', index_col=False, dtype={'zipcode':'S10'})\n",
    "import statsmodels.api as sm\n",
    "add_dummies = pd.get_dummies(nycmodel['zipcode'])\n",
    "add_dummies= add_dummies.applymap(np.int)\n",
    "nycmodel = pd.concat([nycmodel, add_dummies], axis=1)\n",
    "nycmodel.drop(['zipcode','Unnamed: 0'], inplace=True, axis=1)\n",
    "target=nycmodel[['count']]\n",
    "data=nycmodel[[col for col in nycmodel.columns if col not in ['count']]]\n",
    "import sklearn.cross_validation as cv\n",
    "x_train, x_test, y_train, y_test = cv.train_test_split(data, target, test_size=2.0/10, random_state=0)\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('training R^2: %.2f', 0.18730305471123521)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'training R^2: %.2f',ols.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('testing R^2: %.2f', -9.2563315458417126e+17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'testing R^2: %.2f',ols.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('training RMSE:', 1.7698202354548829)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'training RMSE:', mean_squared_error(y_train, ols.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('testing RMSE:', 2.6335145069822397e+18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'testing RMSE:', mean_squared_error(y_test, ols.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#### randomforest\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import linear_model\n",
    "#from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "import math\n",
    "data=x_train\n",
    "target=y_train\n",
    "RFR=RandomForestRegressor(max_features=14,n_estimators=300)\n",
    "RFR.fit(x_train, y_train)\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12627268469109451"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, RFR.predict(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3193203269367448"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, RFR.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /anaconda/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg\n",
      "Requirement already satisfied: numpy in /anaconda/lib/python3.6/site-packages (from xgboost)\n",
      "Requirement already satisfied: scipy in /anaconda/lib/python3.6/site-packages (from xgboost)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip\n",
    "pip.main(['install', 'xgboost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.compat'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-02f78dee7f34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_INSTALLED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#from bayes_opt import bayesian_optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '__main__.compat'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "#from bayes_opt import bayesian_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-bffcb344fdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbayesian_optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlibpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_lib_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPANDAS_INSTALLED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# c_bst_ulong corresponds to bst_ulong defined in xgboost/c_api.h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MultiIndex'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from bayes_opt import bayesian_optimization\n",
    "\n",
    "XGB=xgb.XGBRegressor(max_depth=14,learning_rate=0.1186,n_estimators=463,silent=True,\n",
    "            nthread=-1,gamma=1.0,min_child_weight=6.1929,subsample=0.9675,colsample_bytree=0.8544)\n",
    "XGB.fit(x_train, y_train)\n",
    "XGB.fit(x_test, y_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, XGB.predict(x_train))\n",
    "mean_squared_error(y_test, XGB.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/anaconda/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/5/libgomp.1.dylib\n  Referenced from: /anaconda/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-81e01cc1b6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbayes_opt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbayesian_optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/anaconda/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/5/libgomp.1.dylib\n  Referenced from: /anaconda/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "#### xgboost\n",
    "\n",
    "#### Bayesian Optimization\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from bayes_opt import bayesian_optimization\n",
    "\n",
    "def xgboostcv(max_depth,\n",
    "              learning_rate,\n",
    "              n_estimators,\n",
    "              gamma,\n",
    "              min_child_weight,\n",
    "              subsample,\n",
    "              colsample_bytree,\n",
    "              silent=True,\n",
    "              nthread=-1):\n",
    "    return cross_val_score(xgb.XGBRegressor(max_depth=int(max_depth),\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            n_estimators=int(n_estimators),\n",
    "                                            silent=silent,\n",
    "                                            nthread=nthread,\n",
    "                                            gamma=gamma,\n",
    "                                            min_child_weight=min_child_weight,\n",
    "                                            subsample=subsample,\n",
    "                                            colsample_bytree=colsample_bytree),\n",
    "                           x_train,\n",
    "                           y_train,\n",
    "                           \"mean_squared_error\",\n",
    "                           cv=5).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    xgboostBO = BayesianOptimization(xgboostcv,\n",
    "                                 {'max_depth': (3, 14),\n",
    "                                  'learning_rate': (0.01, 0.2),\n",
    "                                  'n_estimators': (50, 1000),\n",
    "                                  'gamma': (1., 0.01),\n",
    "                                  'min_child_weight': (1, 10),\n",
    "                                  'subsample': (0.5, 1),\n",
    "                                  'colsample_bytree' :(0.5, 1)})\n",
    "    xgboostBO.maximize(init_points=2, n_iter = 28)\n",
    "    print('-'*53)\n",
    "    print('Final Results')\n",
    "    print('XGBOOST: %f' % xgboostBO.res['max']['max_val'])\n",
    "    \n",
    "XGB=xgb.XGBRegressor(max_depth=14,learning_rate=0.1186,n_estimators=463,silent=True,\n",
    "            nthread=-1,gamma=1.0,min_child_weight=6.1929,subsample=0.9675,colsample_bytree=0.8544)\n",
    "XGB.fit(x_train, y_train)\n",
    "XGB.fit(x_test, y_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, XGB.predict(x_train))\n",
    "mean_squared_error(y_test, XGB.predict(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### ridge regression\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn import metrics\n",
    "import math\n",
    "data=x_train\n",
    "target=y_train\n",
    "\n",
    "#### Bayesian Optimization\n",
    "\n",
    "def Ridgecv(alpha):\n",
    "    return cross_val_score(linear_model.Ridge(alpha=float(alpha), random_state=2),\n",
    "                           data, target, 'mean_squared_error', cv=5).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    RidgeBO = BayesianOptimization(Ridgecv, {'alpha': (0, 8)})\n",
    "    RidgeBO.maximize(init_points=2, n_iter = 10)\n",
    "    print('Final Results')\n",
    "    print('Ridge: %f' % RidgeBO.res['max']['max_val'])\n",
    "ridge = linear_model.Ridge(alpha=0.3985)\n",
    "ridge.fit(x_train, y_train)\n",
    "ridge.score(x_train, y_train)\n",
    "ridge.score(x_test, y_test)\n",
    "mean_squared_error(y_train, ridge.predict(x_train))\n",
    "mean_squared_error(y_test, ridge.predict(x_test))\n",
    "\n",
    "#### randomforest\n",
    "\n",
    "RFR=RandomForestRegressor(max_features=14,n_estimators=300)\n",
    "RFR.fit(x_train, y_train)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, RFR.predict(x_train))\n",
    "mean_squared_error(y_test, RFR.predict(x_test))\n",
    "\n",
    "RFR1=RandomForestRegressor(max_features=14,n_estimators=500)\n",
    "RFR1.fit(x_train, y_train)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, RFR1.predict(x_train))\n",
    "mean_squared_error(y_test, RFR1.predict(x_test))\n",
    "\n",
    "#### xgboost\n",
    "\n",
    "#### Bayesian Optimization\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from bayes_opt import bayesian_optimization\n",
    "\n",
    "def xgboostcv(max_depth,\n",
    "              learning_rate,\n",
    "              n_estimators,\n",
    "              gamma,\n",
    "              min_child_weight,\n",
    "              subsample,\n",
    "              colsample_bytree,\n",
    "              silent=True,\n",
    "              nthread=-1):\n",
    "    return cross_val_score(xgb.XGBRegressor(max_depth=int(max_depth),\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            n_estimators=int(n_estimators),\n",
    "                                            silent=silent,\n",
    "                                            nthread=nthread,\n",
    "                                            gamma=gamma,\n",
    "                                            min_child_weight=min_child_weight,\n",
    "                                            subsample=subsample,\n",
    "                                            colsample_bytree=colsample_bytree),\n",
    "                           x_train,\n",
    "                           y_train,\n",
    "                           \"mean_squared_error\",\n",
    "                           cv=5).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    xgboostBO = BayesianOptimization(xgboostcv,\n",
    "                                 {'max_depth': (3, 14),\n",
    "                                  'learning_rate': (0.01, 0.2),\n",
    "                                  'n_estimators': (50, 1000),\n",
    "                                  'gamma': (1., 0.01),\n",
    "                                  'min_child_weight': (1, 10),\n",
    "                                  'subsample': (0.5, 1),\n",
    "                                  'colsample_bytree' :(0.5, 1)})\n",
    "    xgboostBO.maximize(init_points=2, n_iter = 28)\n",
    "    print('-'*53)\n",
    "    print('Final Results')\n",
    "    print('XGBOOST: %f' % xgboostBO.res['max']['max_val'])\n",
    "    \n",
    "XGB=xgb.XGBRegressor(max_depth=14,learning_rate=0.1186,n_estimators=463,silent=True,\n",
    "            nthread=-1,gamma=1.0,min_child_weight=6.1929,subsample=0.9675,colsample_bytree=0.8544)\n",
    "XGB.fit(x_train, y_train)\n",
    "XGB.fit(x_test, y_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, XGB.predict(x_train))\n",
    "mean_squared_error(y_test, XGB.predict(x_test))\n",
    "\n",
    "#### feature importance\n",
    "feature_imprtance = zip(x_trainsub.columns, RFR.feature_importances_)\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')]\n",
    "feature_imprtance = np.array(feature_imprtance, dtype = dtype)\n",
    "feature_sort = np.sort(feature_imprtance, order='importance')[::-1]\n",
    "df=pd.DataFrame(feature_sort)\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "x = np.arange(1, 21)\n",
    "y= df['importance']\n",
    "LABELS = df['feature']\n",
    "plt.figure()\n",
    "plt.bar(x, y, align='center')\n",
    "plt.xticks(x, LABELS)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('RFR Importance')\n",
    "plt.title('RFR importance analysis of top 20 features')\n",
    "plt.show()\n",
    "\n",
    "#### ensemble: using linear regression combine two models: randomforest and xgboost\n",
    "\n",
    "pred_y_test_rf=RFR.predict(x_test)\n",
    "pred_y_test_rf=pd.DataFrame(pred_y_test, columns=['pred_y_testrf'])\n",
    "pred_y_train_rf=RFR.predict(x_train)\n",
    "pred_y_train_rf=pd.DataFrame(pred_y_train, columns=['pred_y_trainrf'])\n",
    "\n",
    "pred_y_test_xgb=XGB.predict(x_test)\n",
    "pred_y_test_xgb=pd.DataFrame(pred_y_test, columns=['pred_y_testxgb'])\n",
    "pred_y_train_xgb=XGB.predict(x_train)\n",
    "pred_y_train_xgb=pd.DataFrame(pred_y_train, columns=['pred_y_trainxgb'])\n",
    "\n",
    "pred_y_train_com=pd.concat([pred_y_trainrf,pred_y_trainxgb], axis=1)\n",
    "from sklearn import linear_model\n",
    "ols = linear_model.LinearRegression(fit_intercept=False)\n",
    "ols.fit(pred_y_train_com, y_train)\n",
    "ols.score(pred_y_train_com, y_train)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "math.sqrt(mean_squared_error(y_train, pred_y_train_com))\n",
    "\n",
    "pred_y_test_com=pd.concat([pred_y_testrf,pred_y_testxgb], axis=1)\n",
    "pred_y_ensemble=ols.fit(pred_y_test_com)\n",
    "math.sqrt(mean_squared_error(y_test, pred_y_ensemble))\n",
    "pred_y_final=pd.concat([y_test, pred_y_testrf,pred_y_testxgb, pred_y_ensemble], axis=1)\n",
    "pred_y_final1=pred_y_final1.applymap(np.int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
